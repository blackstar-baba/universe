"use strict";(self.webpackChunkblackstar_universe=self.webpackChunkblackstar_universe||[]).push([[2758],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>u});var i=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},r=Object.keys(e);for(i=0;i<r.length;i++)a=r[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)a=r[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=i.createContext({}),c=function(e){var t=i.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return i.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var a=e.components,n=e.mdxType,r=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(a),u=n,h=m["".concat(s,".").concat(u)]||m[u]||d[u]||r;return a?i.createElement(h,o(o({ref:t},p),{},{components:a})):i.createElement(h,o({ref:t},p))}));function u(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var r=a.length,o=new Array(r);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,o[1]=l;for(var c=2;c<r;c++)o[c]=a[c];return i.createElement.apply(null,o)}return i.createElement.apply(null,a)}m.displayName="MDXCreateElement"},4743:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>c});var i=a(7462),n=(a(7294),a(3905));const r={},o=void 0,l={unversionedId:"StarRocks/predicate_reorder",id:"StarRocks/predicate_reorder",title:"predicate_reorder",description:"description",source:"@site/docs/StarRocks/predicate_reorder.md",sourceDirName:"StarRocks",slug:"/StarRocks/predicate_reorder",permalink:"/docs/StarRocks/predicate_reorder",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"memo",permalink:"/docs/StarRocks/memo"},next:{title:"temp_partition",permalink:"/docs/StarRocks/temp_partition"}},s={},c=[{value:"description",id:"description",level:2},{value:"Paper 1: Consistently Estimating the Selectivity of Conjuncts of Predicates",id:"paper-1-consistently-estimating-the-selectivity-of-conjuncts-of-predicates",level:3},{value:"Paper 2: Selectivity Estimation for Range Predicates using Lightweight Models",id:"paper-2-selectivity-estimation-for-range-predicates-using-lightweight-models",level:3},{value:"Paper 3: Selectivity Estimation for String Predicates",id:"paper-3-selectivity-estimation-for-string-predicates",level:3},{value:"Document 1: Introducing cost based optimizer to apache hive",id:"document-1-introducing-cost-based-optimizer-to-apache-hive",level:3},{value:"Spark",id:"spark",level:3},{value:"Table data",id:"table-data",level:3},{value:"Table statistics",id:"table-statistics",level:3},{value:"Table query explain",id:"table-query-explain",level:3},{value:"link",id:"link",level:2}],p={toc:c};function d(e){let{components:t,...r}=e;return(0,n.kt)("wrapper",(0,i.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h2",{id:"description"},"description"),(0,n.kt)("p",null,"Reorder predicates based on selectivity which can help node(e.g. HashJoinNode\u3001FilterNode\u3001ScanNode) filter data faster.  "),(0,n.kt)("h3",{id:"paper-1-consistently-estimating-the-selectivity-of-conjuncts-of-predicates"},"Paper 1: ",(0,n.kt)("a",{parentName:"h3",href:"https://courses.cs.washington.edu/courses/cse544/11wi/papers/markl-vldb-2005.pdf"},"Consistently Estimating the Selectivity of Conjuncts of Predicates")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"Cost-based query optimizers need to estimate the selectivity of conjunctive predicates when com- paring alternative query execution plans. To this end, advanced optimizers use multivariate statis- tics (MVS) to improve information about the joint distribution of attribute values in a table. The joint distribution for all columns is almost always too large to store completely, and the resulting use of partial distribution information raises the possibility that multiple, non-equivalent selectivity estimates may be available for a given predicate. Current optimizers use ad hoc methods to ensure that selectivities are estimated in a consistent manner. These methods ignore valuable information and tend to bias the opti- mizer toward query plans for which the least in- formation is available, often yielding poor re- sults. In this paper we present a novel method for consistent selectivity estimation based on the principle of maximum entropy (ME). Our method efficiently exploits all available information and avoids the bias problem. In the ab- sence of detailed knowledge, the ME approach reduces to standard uniformity and independence assumptions. Our implementation using a proto- type version of DB2 UDB shows that ME im- proves the optimizer\u2019s cardinality estimates by orders of magnitude, resulting in better plan quality and significantly reduced query execution times.\n")),(0,n.kt)("p",null,"Provide a novel method for estimating the selectivity of a conjunctive predicate, the method exploits and combines all of the available MVS(multivariate statistics) in a principled, consistent, and unbiased manner.  The technique rests on the principle of maximum entropy (ME). This Paper maybe useful if we have conjunctive predicates.   "),(0,n.kt)("p",null,"\u63d0\u51fa\u4e00\u79cd\u6700\u5927\u71b5 maximum entropy (ME)\u7684\u65b9\u5f0f\u8bc4\u4f30\u5408\u53d6\u8c13\u8bcd\uff08p1^p2^p3\uff09\u9009\u62e9\u5ea6\uff0c\u524d\u63d0\u6761\u4ef6\u662f\u5b58\u50a8\u9009\u5b9a\u7684\u591a\u5143\u7edf\u8ba1\u4fe1\u606fmultivariate statistics\uff08MVS\uff09"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"\u4e3a\u6b64\u6211\u4eec\u9700\u8981\u5e73\u94faCompoundPredicate"),"\uff0c\u8ba1\u7b97\u6982\u7387\uff0c\u5e76\u8ba1\u7b97\u6700\u5927\u71b5\u3002"),(0,n.kt)("h3",{id:"paper-2-selectivity-estimation-for-range-predicates-using-lightweight-models"},"Paper 2: ",(0,n.kt)("a",{parentName:"h3",href:"http://www.vldb.org/pvldb/vol12/p1044-dutt.pdf"},"Selectivity Estimation for Range Predicates using Lightweight Models")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"Query optimizers depend on selectivity estimates of query predicates to produce a good execution plan. When a query contains multiple predicates, today\u2019s optimizers use a va- riety of assumptions, such as independence between predi- cates, to estimate selectivity. While such techniques have the benefit of fast estimation and small memory footprint, they often incur large selectivity estimation errors. In this work, we reconsider selectivity estimation as a regression problem. We explore application of neural networks and tree-based ensembles to the important problem of selectivity estimation of multi-dimensional range predicates. While their straightforward application does not outperform even simple baselines, we propose two simple yet effective design choices, i.e., regression label transformation and feature en- gineering, motivated by the selectivity estimation context. Through extensive empirical evaluation across a variety of datasets, we show that the proposed models deliver both highly accurate estimates as well as fast estimation.\n")),(0,n.kt)("p",null,"Selectivity estimation for range predicates using lightweight models, the lightweight models base on  neural networks "),(0,n.kt)("p",null,"and tree-based ensembles. Range Predicates e.g.  10< A1 <20.  This Paper maybe useful if we have multi-range predicate. "),(0,n.kt)("p",null,"\u8bad\u7ec3\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edcneural networks\uff08NN\uff09\u548c XGBoost\u57fa\u4e8e\u6811\u7684\u96c6\u6210tree-based ensembles.\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u542f\u53d1\u5f0f\u7684\u8bc4\u4f30\u65b9\u5f0f\u4f5c\u4e3a\u8865\u5145"),(0,n.kt)("p",null,"AVI\uff1aattribute value independence\uff08\u5c5e\u6027\u503c\u72ec\u7acb\uff09\u5927\u591a\u6570\u6570\u636e\u5e93\u4f7f\u7528\u7684\u65b9\u5f0f"),(0,n.kt)("p",null,"STHoles\uff1aA Multidimensional Workload-Aware Histogram\uff0cSTHoles \u76f4\u65b9\u56fe\u662f\u5728\u4e0d\u68c0\u67e5\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\u6784\u5efa\u7684\uff0c\u800c\u53ea\u662f\u901a\u8fc7\u5206\u6790\u67e5\u8be2\u7ed3\u679c"),(0,n.kt)("p",null,"STHoles works good on 2D-predicates, but not on 4D-predicates, this method can works good on 4D-predicates"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Selectivity_estimation_for_range_predicates",src:a(4397).Z,width:"864",height:"452"})),(0,n.kt)("h3",{id:"paper-3-selectivity-estimation-for-string-predicates"},"Paper 3: ",(0,n.kt)("a",{parentName:"h3",href:"http://www.cs.columbia.edu/~gravano/Papers/2004/icde04.pdf"},"Selectivity Estimation for String Predicates")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"we exploit representative query workloads to learn an appropriate combination model for the selectivity estimates of candidate identifying substrings over a particular database. The learnt model is then applied at run time to efficiently and accurately estimate the string predicate selectivity.\n")),(0,n.kt)("p",null," Selectivity estimators for string predicates, need lean an ",(0,n.kt)("inlineCode",{parentName:"p"},"appropriate combination model")," for the selectivity estimates which  use Markov tables and regression tree models.  This Paper maybe useful if we have string predicates.  "),(0,n.kt)("p",null,"\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u5b57\u7b26\u4e32\u8c13\u8bcd\u9009\u62e9\u5ea6\u7684\u65b9\u6cd5\uff0c\u5e38\u7528\u8bc4\u4f30\u65b9\u6cd5\uff1apruned suffix trees or Markov tables\uff08\u4fee\u526a\u540e\u7684\u540e\u7f00\u6811\u6216\u8005\u9a6c\u5c14\u53ef\u592b\u8868\uff09"),(0,n.kt)("p",null,"\u5229\u7528\u4e00\u5b9a\u7684\u67e5\u8be2\u8d1f\u8f7d\u8bad\u7ec3\u5b66\u4e60\u6a21\u578b\uff0c\u7136\u540e\u7528\u5b66\u4e60\u5230\u7684\u6a21\u578b\u6765\u4f30\u8ba1\u5b57\u7b26\u4e32\u8c13\u8bcd\u7684\u9009\u62e9\u6027\uff0c\u4f7f\u7528\u9a6c\u5c14\u79d1\u592b\u8868\u548c\u56de\u5f52\u6811\u6a21\u578b"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Selectivity_estimation_for_string_predicates",src:a(9045).Z,width:"1318",height:"656"})),(0,n.kt)("h3",{id:"document-1-introducing-cost-based-optimizer-to-apache-hive"},"Document 1: ",(0,n.kt)("a",{parentName:"h3",href:"https://cwiki.apache.org/confluence/download/attachments/27362075/CBO-2.pdf"},"Introducing cost based optimizer to apache hive")),(0,n.kt)("p",null,"In Section ",(0,n.kt)("inlineCode",{parentName:"p"},"Filter Selectivity"),",we can get some algorithms without histogram:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"\u2022 Equality  Predicates  where   one side    is  a   literal =   1/V(R,  A)\n\u2022 Equality  Predicate   when    both    sides   are not literals    =   1/max   (V(R,   A), V(R,    B))\n\u2022 In    Equality    Predicates  (Less/Greater   than)   =   1/3\n\u2022 Not   Equal   =   (V(R,   A)  -1)/V(R,    A)\n\u2022 OR     Condition   =   n*(1    \u2013(1-m1/n)(1-m2/n))  where   n   is  the     total   number  of  tuples \nfrom    child   and m1  and m2  is   the    expected    number  of   tuples  from   each    part    of   the    \ndisjunction predicate.\n\u2022 AND    condition   =   product     of  selectivity     of  individual  leaf    predicates in   the    \nconjunctive predicate\n")),(0,n.kt)("p",null,"Code link\uff1a",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java"},"https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/optimizer/calcite/stats/FilterSelectivityEstimator.java")),(0,n.kt)("p",null,"Heuristics \u542f\u53d1\u5f0f"),(0,n.kt)("p",null,"Histogram \u7edf\u8ba1\u76f4\u65b9\u56fe"),(0,n.kt)("h3",{id:"spark"},"Spark"),(0,n.kt)("p",null,"code link: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/spark/blob/ddc61e62b9af5deff1b93e22f466f2a13f281155/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation.scala"},"https://github.com/apache/spark/blob/ddc61e62b9af5deff1b93e22f466f2a13f281155/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/statsEstimation/FilterEstimation.scala"),"  calculateFilterSelectivity"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-scala"},"def calculateFilterSelectivity(condition: Expression, update: Boolean = true): Option[Double] = {\n    condition match {\n      case And(cond1, cond2) =>\n        val percent1 = calculateFilterSelectivity(cond1, update).getOrElse(1.0)\n        val percent2 = calculateFilterSelectivity(cond2, update).getOrElse(1.0)\n        Some(percent1 * percent2)\n\n      case Or(cond1, cond2) =>\n        val percent1 = calculateFilterSelectivity(cond1, update = false).getOrElse(1.0)\n        val percent2 = calculateFilterSelectivity(cond2, update = false).getOrElse(1.0)\n        Some(percent1 + percent2 - (percent1 * percent2))\n\n      // Not-operator pushdown\n      case Not(And(cond1, cond2)) =>\n        calculateFilterSelectivity(Or(Not(cond1), Not(cond2)), update = false)\n\n      // Not-operator pushdown\n      case Not(Or(cond1, cond2)) =>\n        calculateFilterSelectivity(And(Not(cond1), Not(cond2)), update = false)\n\n      // Collapse two consecutive Not operators which could be generated after Not-operator pushdown\n      case Not(Not(cond)) =>\n        calculateFilterSelectivity(cond, update = false)\n\n      // The foldable Not has been processed in the ConstantFolding rule\n      // This is a top-down traversal. The Not could be pushed down by the above two cases.\n      case Not(l @ Literal(null, _)) =>\n        calculateSingleCondition(l, update = false).map(boundProbability(_))\n\n      case Not(cond) =>\n        calculateFilterSelectivity(cond, update = false) match {\n          case Some(percent) => Some(1.0 - percent)\n          case None => None\n        }\n\n      case _ =>\n        calculateSingleCondition(condition, update).map(boundProbability(_))\n    }\n  }\n")),(0,n.kt)("p",null,"Contrast\uff1a"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Paper or Document"),(0,n.kt)("th",{parentName:"tr",align:null},"Range"),(0,n.kt)("th",{parentName:"tr",align:null},"Need Histogram"),(0,n.kt)("th",{parentName:"tr",align:null},"Need Model"),(0,n.kt)("th",{parentName:"tr",align:null},"Result"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Consistently Estimating the Selectivity of Conjuncts of Predicates"),(0,n.kt)("td",{parentName:"tr",align:null},"Conjunction Predicates"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Good")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Selectivity Estimation for Range Predicates using Lightweight Models"),(0,n.kt)("td",{parentName:"tr",align:null},"Range Pridiates"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"Good")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Selectivity Estimation for String Predicates"),(0,n.kt)("td",{parentName:"tr",align:null},"String Pridiates"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes"),(0,n.kt)("td",{parentName:"tr",align:null},"Good")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Introducing cost based optimizer to apache hive"),(0,n.kt)("td",{parentName:"tr",align:null},"Almost All"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Medium")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Spark"),(0,n.kt)("td",{parentName:"tr",align:null},"Almost All"),(0,n.kt)("td",{parentName:"tr",align:null},"Yes, but can no need, use simple statistics"),(0,n.kt)("td",{parentName:"tr",align:null},"No"),(0,n.kt)("td",{parentName:"tr",align:null},"Medium")))),(0,n.kt)("p",null,"Conclusion\uff1a"),(0,n.kt)("p",null,"We don't have histograms on the table column now, so we can use algorithms which in Hive or Spark before we add histogram. The algorithms in Spark can use  column statistics  or histogram which hive hasn't used, so i decided to transplant  the spark's algorithm."),(0,n.kt)("p",null,"Result:"),(0,n.kt)("h3",{id:"table-data"},"Table data"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-sql"},"mysql> select * from test.table1;\n+--------+----------+----------+------+\n| siteid | citycode | username | pv   |\n+--------+----------+----------+------+\n|      3 |        3 | my       |    3 |\n|      1 |        1 | my       |    1 |\n|      2 |        2 | my       |    2 |\n+--------+----------+----------+------+\n3 rows in set (0.05 sec)\n")),(0,n.kt)("h3",{id:"table-statistics"},"Table statistics"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-sql"},"mysql> select * from _statistics_.table_statistic_v1;\n+----------+-------------+-------+-------------+----------------------+-----------+-----------+----------------+------------+------+------+---------------------+\n| table_id | column_name | db_id | table_name  | db_name              | row_count | data_size | distinct_count | null_count | max  | min  | update_time         |\n+----------+-------------+-------+-------------+----------------------+-----------+-----------+----------------+------------+------+------+---------------------+\n|    10005 | siteid      | 10003 | test.table1 | default_cluster:test |         3 |        12 |              3 |          0 | 3    | 1    | 2022-04-15 14:27:52 |\n|    10005 | username    | 10003 | test.table1 | default_cluster:test |         3 |         6 |              1 |          0 | my   | my   | 2022-04-15 14:27:52 |\n|    10005 | citycode    | 10003 | test.table1 | default_cluster:test |         3 |         6 |              3 |          0 | 3    | 1    | 2022-04-15 14:27:52 |\n+----------+-------------+-------+-------------+----------------------+-----------+-----------+----------------+------------+------+------+---------------------+\n3 rows in set (0.05 sec)\n")),(0,n.kt)("h3",{id:"table-query-explain"},"Table query explain"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-sql"},"mysql> explain select * from test.table1 where citycode < 2 and siteid > 3;\n+-----------------------------------------------------------------------------+\n| Explain String                                                              |\n+-----------------------------------------------------------------------------+\n| PLAN FRAGMENT 0                                                             |\n|  OUTPUT EXPRS:1: siteid | 2: citycode | 3: username | 4: pv                 |\n|   PARTITION: UNPARTITIONED                                                  |\n|                                                                             |\n|   RESULT SINK                                                               |\n|                                                                             |\n|   1:EXCHANGE                                                                |\n|                                                                             |\n| PLAN FRAGMENT 1                                                             |\n|  OUTPUT EXPRS:                                                              |\n|   PARTITION: RANDOM                                                         |\n|                                                                             |\n|   STREAM DATA SINK                                                          |\n|     EXCHANGE ID: 01                                                         |\n|     UNPARTITIONED                                                           |\n|                                                                             |\n|   0:OlapScanNode                                                            |\n|      TABLE: table1                                                          |\n|      PREAGGREGATION: OFF. Reason: None aggregate function                   |\n|      PREDICATES: 1: siteid > 3, 2: citycode < 2                             |\n|      partitions=1/1                                                         |\n|      rollup: table1                                                         |\n|      tabletRatio=10/10                                                      |\n|      tabletList=10007,10009,10011,10013,10015,10017,10019,10021,10023,10025 |\n|      cardinality=1                                                          |\n|      avgRowSize=4.0                                                         |\n|      numNodes=0                                                             |\n+-----------------------------------------------------------------------------+\n27 rows in set (0.03 sec)\n")),(0,n.kt)("p",null,"expression ",(0,n.kt)("inlineCode",{parentName:"p"},"citycode < 2")," after expression ",(0,n.kt)("inlineCode",{parentName:"p"},"siteid > 3")," now!"),(0,n.kt)("h2",{id:"link"},"link"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Spark Filter predicate reoder: ",(0,n.kt)("a",{parentName:"p",href:"https://issues.apache.org/jira/browse-33979"},"https://issues.apache.org/jira/browse-33979"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Issue: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/StarRocks/starrocks/issues/4024"},"https://github.com/StarRocks/starrocks/issues/4024"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Query Plan Optimization: ",(0,n.kt)("strong",{parentName:"p"},"Join Predicate Ordering")," ",(0,n.kt)("a",{parentName:"p",href:"https://medium.com/hyrise/query-plan-optimization-join-predicate-ordering-34c2fbe6591a"},"https://medium.com/hyrise/query-plan-optimization-join-predicate-ordering-34c2fbe6591a"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Predicate Ordering ",(0,n.kt)("a",{parentName:"p",href:"https://docs.oracle.com/cd/B10500_01/appdev.920/a96595/dci08opt.htm#1006512"},"https://docs.oracle.com/cd/B10500_01/appdev.920/a96595/dci08opt.htm#1006512"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"concepts-selectivity-predicates ",(0,n.kt)("a",{parentName:"p",href:"https://www.ibm.com/docs/en/db2/11.5?topic=concepts-selectivity-predicates"},"https://www.ibm.com/docs/en/db2/11.5?topic=concepts-selectivity-predicates"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Query Plan Optimization: ",(0,n.kt)("strong",{parentName:"p"},"Join Predicate Ordering "),(0,n.kt)("a",{parentName:"p",href:"https://medium.com/hyrise/query-plan-optimization-join-predicate-ordering-34c2fbe6591a"},"https://medium.com/hyrise/query-plan-optimization-join-predicate-ordering-34c2fbe6591a")))))}d.isMDXComponent=!0},4397:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/Selectivity_estimation_for_range_predicates-340aef1e40f1040ada1c4801cab1f13a.png"},9045:(e,t,a)=>{a.d(t,{Z:()=>i});const i=a.p+"assets/images/Selectivity_estimation_for_string_predicates-c8db2d07c683144ddb591904414f0f71.png"}}]);